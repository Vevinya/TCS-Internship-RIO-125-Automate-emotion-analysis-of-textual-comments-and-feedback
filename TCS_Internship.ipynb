{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCS-Internship.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJovozk8H67n"
      },
      "source": [
        "## **Data Intialisation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQRCTfedoH-Z",
        "outputId": "13c13a1e-4327-48ed-f250-6f51f22e92f5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3Jh_pAip9PV",
        "outputId": "5d5b4f2c-3116-4ade-8b44-a3147f2c8ec2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE2cuuyIqAF1"
      },
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/text_emotion.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "aGVd2XTn5mil",
        "outputId": "2aa1d82b-7274-4857-cf96-339c54b01f5c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>empty</td>\n",
              "      <td>xoshayzers</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>wannamama</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>coolfunky</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>czareaquino</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>xkilljoyx</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     tweet_id  ...                                            content\n",
              "0  1956967341  ...  @tiffanylue i know  i was listenin to bad habi...\n",
              "1  1956967666  ...  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2  1956967696  ...                Funeral ceremony...gloomy friday...\n",
              "3  1956967789  ...               wants to hang out with friends SOON!\n",
              "4  1956968416  ...  @dannycastillo We want to trade with someone w...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAP64fOh5rUf",
        "outputId": "c1a148d8-75c7-4789-ce4b-30f50617b8ba"
      },
      "source": [
        "df['sentiment'].unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
              "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbhMg9zT5z_R",
        "outputId": "73679868-ce2e-41e1-f1fb-e01dd51825c8"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c072EJZ-6lhK",
        "outputId": "73cc8f5c-5d5f-4f7a-a998-252da2663e29"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjUvhkPA4ceM"
      },
      "source": [
        "# Dropping rows with other emotion labels\n",
        "df = df.drop(df[df.sentiment == 'anger'].index)\n",
        "df = df.drop(df[df.sentiment == 'boredom'].index)\n",
        "df = df.drop(df[df.sentiment == 'enthusiasm'].index)\n",
        "df = df.drop(df[df.sentiment == 'empty'].index)\n",
        "df = df.drop(df[df.sentiment == 'fun'].index)\n",
        "df = df.drop(df[df.sentiment == 'relief'].index)\n",
        "df = df.drop(df[df.sentiment == 'surprise'].index)\n",
        "df = df.drop(df[df.sentiment == 'hate'].index)\n",
        "df = df.drop(df[df.sentiment == 'love'].index)\n",
        "df = df.drop(df[df.sentiment == 'neutral'].index)\n",
        "df = df.drop(df[df.sentiment == 'worry'].index)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKb63hIH6t70"
      },
      "source": [
        "df=df.drop([\"tweet_id\",\"author\"],axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pFGC8ZcX7qj6",
        "outputId": "50d03fdc-df23-475b-cd67-70406f148e6d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sadness</td>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sadness</td>\n",
              "      <td>@charviray Charlene my love. I miss you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sadness</td>\n",
              "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                            content\n",
              "1   sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2   sadness                Funeral ceremony...gloomy friday...\n",
              "6   sadness  I should be sleep, but im not! thinking about ...\n",
              "8   sadness            @charviray Charlene my love. I miss you\n",
              "9   sadness         @kelcouch I'm sorry  at least it's Friday?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haKmx5V_5U4e",
        "outputId": "f2bea2fd-8fee-4ab7-96a5-34b06377254f"
      },
      "source": [
        "df.shape\n",
        "df['sentiment'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "happiness    5209\n",
              "sadness      5165\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7cvPX7JICbj"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR3eCogp5gHU"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "#Encoding output labels 'sadness' as '1' & 'happiness' as '0'\n",
        "lbl_enc = preprocessing.LabelEncoder()\n",
        "df['label']= lbl_enc.fit_transform(df.sentiment.values)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZJDs7Nf54Y-",
        "outputId": "257ea4a0-8ab7-4d36-e6c3-4d778afbc68b"
      },
      "source": [
        "print(df['sentiment'].value_counts())\n",
        "print(df['label'].value_counts())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "happiness    5209\n",
            "sadness      5165\n",
            "Name: sentiment, dtype: int64\n",
            "0    5209\n",
            "1    5165\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "058vLEw56Z7W"
      },
      "source": [
        "#Encoding output labels 'happiness' as '0' \n",
        "#Encoding output labels 'sadness' as '1' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNozfiXH7v84"
      },
      "source": [
        "#Making all review to lowercase\n",
        "df['content'] = df['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBefQZSx76LH"
      },
      "source": [
        "# Removing Punctuation, Symbols\n",
        "df['content'] = df['content'].str.replace('[^\\w\\s]',' ')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTEIlLvr8t9I",
        "outputId": "fa29dd20-f687-4d0c-a30e-2c192b8af4b8"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "stops.remove(\"not\")\n",
        "stops.remove(\"but\")\n",
        "stops.remove(\"no\")\n",
        "df['content'] = df['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stops))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyZTQ5pv81rb"
      },
      "source": [
        "import re\n",
        "#Correcting Letter Repetitions\n",
        "def de_repeat(text):\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "    return pattern.sub(r\"\\1\\1\", text)\n",
        "\n",
        "df['content'] = df['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gexykdp69HHn"
      },
      "source": [
        "# Code to find the top 10,000 rarest words appearing in the data\n",
        "freq = pd.Series(' '.join(df['content']).split()).value_counts()[-10000:]\n",
        "\n",
        "# Removing all those rarely appearing words from the data\n",
        "freq = list(freq.index)\n",
        "df['content'] = df['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rt42kppR9In3",
        "outputId": "68702cf2-4c78-470a-cfc5-0012b2bbc61b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>n bed headache ughh waitin call</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sadness</td>\n",
              "      <td>sleep but im not thinking old friend want but ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sadness</td>\n",
              "      <td>love miss</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sadness</td>\n",
              "      <td>sorry least friday</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                            content  label\n",
              "1   sadness                    n bed headache ughh waitin call      1\n",
              "2   sadness                     funeral ceremony gloomy friday      1\n",
              "6   sadness  sleep but im not thinking old friend want but ...      1\n",
              "8   sadness                                          love miss      1\n",
              "9   sadness                                 sorry least friday      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtcHokQb_KMk"
      },
      "source": [
        "#Function to split string to tokens\n",
        "def identify_tokens(row):\n",
        "    tokens = nltk.word_tokenize(row)\n",
        "    token_words = [w for w in tokens if w.isalpha()]\n",
        "    return token_words"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7S1X2sW_LUF"
      },
      "source": [
        "#Tokenization of DataFrame\n",
        "df['content'] = df[\"content\"].apply(identify_tokens)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL2HAkWC7n7k",
        "outputId": "6340e44a-7313-49e2-e615-fb538f00ac12"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "#Funtion for lemmatizing the list of words\n",
        "def lem_list(row):\n",
        "    lemmatized_list = [lemmatizer.lemmatize(word) for word in row]\n",
        "    return (lemmatized_list)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYGR2Mhp9-xq"
      },
      "source": [
        "#Lemmatize of the dataframe\n",
        "df['content'] = df['content'].apply(lem_list)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "183IG0zH-hLT",
        "outputId": "0eac4265-c549-4602-e3b9-4b2469a74637"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>[n, bed, headache, ughh, waitin, call]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>[funeral, ceremony, gloomy, friday]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sadness</td>\n",
              "      <td>[sleep, but, im, not, thinking, old, friend, w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sadness</td>\n",
              "      <td>[love, miss]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sadness</td>\n",
              "      <td>[sorry, least, friday]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                            content  label\n",
              "1   sadness             [n, bed, headache, ughh, waitin, call]      1\n",
              "2   sadness                [funeral, ceremony, gloomy, friday]      1\n",
              "6   sadness  [sleep, but, im, not, thinking, old, friend, w...      1\n",
              "8   sadness                                       [love, miss]      1\n",
              "9   sadness                             [sorry, least, friday]      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G0ynISl-uT3"
      },
      "source": [
        "#Function to join the processed words\n",
        "def rejoin_words(row):\n",
        "    joined_words = ( \" \".join(row))\n",
        "    return joined_words"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkiXvMll_svH"
      },
      "source": [
        "#Joining the processed words in the data_frame\n",
        "df['content'] = df[\"content\"].apply(rejoin_words)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3G_0qnEHADvb",
        "outputId": "90d64abf-a3bd-430e-b5dd-95f269f6f3e2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>n bed headache ughh waitin call</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>funeral ceremony gloomy friday</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sadness</td>\n",
              "      <td>sleep but im not thinking old friend want but ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sadness</td>\n",
              "      <td>love miss</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sadness</td>\n",
              "      <td>sorry least friday</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                            content  label\n",
              "1   sadness                    n bed headache ughh waitin call      1\n",
              "2   sadness                     funeral ceremony gloomy friday      1\n",
              "6   sadness  sleep but im not thinking old friend want but ...      1\n",
              "8   sadness                                          love miss      1\n",
              "9   sadness                                 sorry least friday      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvqPK04cIQUt"
      },
      "source": [
        "# **Splitting dataset I**\n",
        "### **NUMPY array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvboAMIPAO-L"
      },
      "source": [
        "#x contains review and y contain sentiment\n",
        "x=df.iloc[:,1].values\n",
        "y=df.iloc[:,2].values"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl0EKDi-A609"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Splitting into training and testing data\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcbyyIw_cNN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f465915e-9756-406d-9336-b4e4d87a85de"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3424,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kEzTt8kcOAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c24967-d293-4b36-f66f-992b7a0e92f2"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6950,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYECbONyb5mW"
      },
      "source": [
        "# **Splitting Dataset II**\n",
        "### **Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MWHFm90Ok38"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x1_train,x1_test,y1_train,y1_test=train_test_split(df[['content']],df[['label']])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2g5-mrCHD-",
        "outputId": "aced4ff7-9840-4fce-8738-2d20ffe9d66c"
      },
      "source": [
        "x1_test.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2594, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYSNSCzNcHFL",
        "outputId": "4d86e173-e219-4024-9364-236ef8638e5e"
      },
      "source": [
        "x1_train.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7780, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR1aRNX1crv9"
      },
      "source": [
        "# **Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iCFkicQLa7K"
      },
      "source": [
        "### **TFIDF Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2dmUvD0Cida"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D6GjaUMC1wy"
      },
      "source": [
        "# Extracting TF-IDF parameters\n",
        "tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n",
        "x_train_tfidf = tfidf.fit_transform(x_train)\n",
        "x_val_tfidf = tfidf.fit_transform(x_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzLL3sRHLg1i"
      },
      "source": [
        "### **Count Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVWg2xpJFEQH"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnYs9wRPE5Xj"
      },
      "source": [
        "# Extracting Count Vectors Parameters\n",
        "count_vect = CountVectorizer(analyzer='word')\n",
        "count_vect.fit(df['content'])\n",
        "x_train_count =  count_vect.transform(x_train)\n",
        "x_val_count =  count_vect.transform(x_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im3jIawMLy8x"
      },
      "source": [
        "### **Feature Extraction Using Lexical Methods**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Br8HvLModb",
        "outputId": "b81bd683-ff07-42d6-c270-3d11e94da794"
      },
      "source": [
        "pip install --upgrade vaderSentiment"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/fc/310e16254683c1ed35eeb97386986d6c00bc29df17ce280aed64d55537e9/vaderSentiment-3.3.2-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 19.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP1hB8JkDFOy"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TCOikAtrN943",
        "outputId": "248a4cbc-5482-4282-8f19-d4b2feb1cd8b"
      },
      "source": [
        "x1_train.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28474</th>\n",
              "      <td>morning sunshine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27067</th>\n",
              "      <td>watching gon na grand day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39436</th>\n",
              "      <td>way watch star trek imax baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34802</th>\n",
              "      <td>although killing right la</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5960</th>\n",
              "      <td>got people let skip sci pratical becos skola i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 content\n",
              "28474                                   morning sunshine\n",
              "27067                          watching gon na grand day\n",
              "39436                      way watch star trek imax baby\n",
              "34802                          although killing right la\n",
              "5960   got people let skip sci pratical becos skola i..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5932OeL7L66j"
      },
      "source": [
        "x1_train['negative'] = x1_train['content'].apply(lambda x: analyser.polarity_scores(x)[\"neg\"])\n",
        "x1_test['negative'] = x1_test['content'].apply(lambda x: analyser.polarity_scores(x)[\"neg\"])\n",
        "x1_train['positive'] = x1_train['content'].apply(lambda x: analyser.polarity_scores(x)[\"pos\"])\n",
        "x1_test['positive'] = x1_test['content'].apply(lambda x: analyser.polarity_scores(x)[\"pos\"])\n",
        "x1_train['neutral'] = x1_train['content'].apply(lambda x: analyser.polarity_scores(x)[\"neu\"])\n",
        "x1_test['neutral'] = x1_test['content'].apply(lambda x: analyser.polarity_scores(x)[\"neu\"])\n",
        "x1_train['compound'] = x1_train['content'].apply(lambda x: analyser.polarity_scores(x)[\"compound\"])\n",
        "x1_test['compound'] = x1_test['content'].apply(lambda x: analyser.polarity_scores(x)[\"compound\"])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwnWQI9qP-o9"
      },
      "source": [
        "from textblob import TextBlob\n",
        "x1_train['subjectivity'] = x1_train['content'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
        "x1_test['subjectivity'] = x1_test['content'].apply(lambda x: TextBlob(x).sentiment.subjectivity)\n",
        "x1_train['polarity'] = x1_train['content'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "x1_test['polarity'] = x1_test['content'].apply(lambda x: TextBlob(x).sentiment.polarity)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ou7Y2WMN5y8q",
        "outputId": "300767fc-17f3-4e95-e2c9-35c6bd017406"
      },
      "source": [
        "x1_train.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "      <th>neutral</th>\n",
              "      <th>compound</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28474</th>\n",
              "      <td>morning sunshine</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.762</td>\n",
              "      <td>0.238</td>\n",
              "      <td>0.4939</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27067</th>\n",
              "      <td>watching gon na grand day</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.429</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.4588</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39436</th>\n",
              "      <td>way watch star trek imax baby</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34802</th>\n",
              "      <td>although killing right la</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.405</td>\n",
              "      <td>-0.6597</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5960</th>\n",
              "      <td>got people let skip sci pratical becos skola i...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.249</td>\n",
              "      <td>0.751</td>\n",
              "      <td>0.5621</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 content  ...  polarity\n",
              "28474                                   morning sunshine  ...  0.000000\n",
              "27067                          watching gon na grand day  ...  0.500000\n",
              "39436                      way watch star trek imax baby  ...  0.000000\n",
              "34802                          although killing right la  ...  0.285714\n",
              "5960   got people let skip sci pratical becos skola i...  ...  0.400000\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNLYqxDM13hc"
      },
      "source": [
        "# **Training of Models**\n",
        "## **I)Using TF-IDF Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkqTCL4-2w1_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u--LyUS2YgS",
        "outputId": "dc2bcf3a-f603-47eb-c5c7-7ed96cca0907"
      },
      "source": [
        "# Model 1: Multinomial Naive Bayes Classifier\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train_tfidf, y_train)\n",
        "y_pred = nb.predict(x_val_tfidf)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5262850467289719\n",
            "[[895 837]\n",
            " [785 907]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.52      0.52      1732\n",
            "           1       0.52      0.54      0.53      1692\n",
            "\n",
            "    accuracy                           0.53      3424\n",
            "   macro avg       0.53      0.53      0.53      3424\n",
            "weighted avg       0.53      0.53      0.53      3424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcsY8yyw2ZgL",
        "outputId": "299db79a-bfc7-4b55-c315-c33ed35a2e3e"
      },
      "source": [
        "# Model 2: Linear SVM\n",
        "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
        "lsvm.fit(x_train_tfidf, y_train)\n",
        "y_pred = lsvm.predict(x_val_tfidf)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5084696261682243\n",
            "[[945 948]\n",
            " [735 796]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.50      0.53      1893\n",
            "           1       0.46      0.52      0.49      1531\n",
            "\n",
            "    accuracy                           0.51      3424\n",
            "   macro avg       0.51      0.51      0.51      3424\n",
            "weighted avg       0.52      0.51      0.51      3424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LnRYzDA2bkj",
        "outputId": "9ff250e8-c139-45bc-f024-8fb46792a21c"
      },
      "source": [
        "# Model 3: Logistic Regression\n",
        "logreg = LogisticRegression(C=1)\n",
        "logreg.fit(x_train_tfidf, y_train)\n",
        "y_pred = logreg.predict(x_val_tfidf)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5204439252336449\n",
            "[[924 886]\n",
            " [756 858]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.51      0.53      1810\n",
            "           1       0.49      0.53      0.51      1614\n",
            "\n",
            "    accuracy                           0.52      3424\n",
            "   macro avg       0.52      0.52      0.52      3424\n",
            "weighted avg       0.52      0.52      0.52      3424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7oltdA22ffa",
        "outputId": "b6944228-2cd5-43f4-d527-eca925ee8fa4"
      },
      "source": [
        "# Model 4: Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=500)\n",
        "rf.fit(x_train_tfidf, y_train)\n",
        "y_pred = rf.predict(x_val_tfidf)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5143107476635514\n",
            "[[815 798]\n",
            " [865 946]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.51      0.49      1613\n",
            "           1       0.54      0.52      0.53      1811\n",
            "\n",
            "    accuracy                           0.51      3424\n",
            "   macro avg       0.51      0.51      0.51      3424\n",
            "weighted avg       0.52      0.51      0.51      3424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO85zdwSLqKg"
      },
      "source": [
        "## **II) Using Count Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y35InOULDChe",
        "outputId": "51872ea9-2422-4bd8-b24b-4a8f8b658a78"
      },
      "source": [
        "# Model 1: Multinomial Naive Bayes Classifier\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train_count, y_train)\n",
        "y_pred = nb.predict(x_val_count)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8057827102803738\n",
            "[[1351  336]\n",
            " [ 329 1408]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80      1687\n",
            "           1       0.81      0.81      0.81      1737\n",
            "\n",
            "    accuracy                           0.81      3424\n",
            "   macro avg       0.81      0.81      0.81      3424\n",
            "weighted avg       0.81      0.81      0.81      3424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftxooPTG3z_P",
        "outputId": "1a9799c3-c1f8-4956-db8c-db1bc87b041f"
      },
      "source": [
        "# Model 2: Linear SVM\n",
        "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
        "lsvm.fit(x_train_count, y_train)\n",
        "y_pred = lsvm.predict(x_val_count)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.803446261682243\n",
            "[[1401  394]\n",
            " [ 279 1350]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.78      0.81      1795\n",
            "           1       0.77      0.83      0.80      1629\n",
            "\n",
            "    accuracy                           0.80      3424\n",
            "   macro avg       0.80      0.80      0.80      3424\n",
            "weighted avg       0.81      0.80      0.80      3424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQtEvNq1322Z",
        "outputId": "455879e7-df4e-4fa5-8e57-4aa1117eb3ea"
      },
      "source": [
        "# Model 3: Logistic Regression\n",
        "logreg = LogisticRegression(C=1)\n",
        "logreg.fit(x_train_count, y_train)\n",
        "y_pred = logreg.predict(x_val_count)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8081191588785047\n",
            "[[1382  359]\n",
            " [ 298 1385]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.81      1741\n",
            "           1       0.79      0.82      0.81      1683\n",
            "\n",
            "    accuracy                           0.81      3424\n",
            "   macro avg       0.81      0.81      0.81      3424\n",
            "weighted avg       0.81      0.81      0.81      3424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ5ndZUR35Km",
        "outputId": "a860b682-6b6c-4f71-82c6-a1fb3606a4f5"
      },
      "source": [
        "# Model 4: Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=500)\n",
        "rf.fit(x_train_count, y_train)\n",
        "y_pred = rf.predict(x_val_count)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7964369158878505\n",
            "[[1347  364]\n",
            " [ 333 1380]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.79      0.79      1711\n",
            "           1       0.79      0.81      0.80      1713\n",
            "\n",
            "    accuracy                           0.80      3424\n",
            "   macro avg       0.80      0.80      0.80      3424\n",
            "weighted avg       0.80      0.80      0.80      3424\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN_PZVW-5KsD"
      },
      "source": [
        "## **III) Using Vader Sentiments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE-wLgiFUamm",
        "outputId": "bb0b17be-aded-468e-eb78-9f27285bcc59"
      },
      "source": [
        "# Model 1: Linear SVM\n",
        "lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
        "lsvm.fit(x1_train.drop(['content'], axis=1), y1_train)\n",
        "y_pred = lsvm.predict(x1_test.drop(['content'], axis=1))\n",
        "print(accuracy_score(y_pred, y1_test))\n",
        "print(confusion_matrix(y_pred, y1_test))\n",
        "print(classification_report(y_pred, y1_test))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7478797224363917\n",
            "[[1168  537]\n",
            " [ 117  772]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.69      0.78      1705\n",
            "           1       0.59      0.87      0.70       889\n",
            "\n",
            "    accuracy                           0.75      2594\n",
            "   macro avg       0.75      0.78      0.74      2594\n",
            "weighted avg       0.80      0.75      0.75      2594\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUq74yjyXwwy",
        "outputId": "b5201d51-56c6-44bb-c698-684289bfaacb"
      },
      "source": [
        "# Model 2: Logistic Regression\n",
        "logreg = LogisticRegression(C=1)\n",
        "logreg.fit(x1_train.drop(['content'], axis=1), y1_train)\n",
        "y_pred = logreg.predict(x1_test.drop(['content'], axis=1))\n",
        "print(accuracy_score(y_pred, y1_test))\n",
        "print(confusion_matrix(y_pred, y1_test))\n",
        "print(classification_report(y_pred, y1_test))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7490362374710872\n",
            "[[978 344]\n",
            " [307 965]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.74      0.75      1322\n",
            "           1       0.74      0.76      0.75      1272\n",
            "\n",
            "    accuracy                           0.75      2594\n",
            "   macro avg       0.75      0.75      0.75      2594\n",
            "weighted avg       0.75      0.75      0.75      2594\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Vz8Y23X_vF",
        "outputId": "48ad0464-6fcb-4979-f8bf-11de2bfd6f95"
      },
      "source": [
        "# Model 3: Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=500)\n",
        "rf.fit(x1_train.drop(['content'], axis=1), y1_train)\n",
        "y_pred = rf.predict(x1_test.drop(['content'], axis=1))\n",
        "print(accuracy_score(y_pred, y1_test))\n",
        "print(confusion_matrix(y_pred, y1_test))\n",
        "print(classification_report(y_pred, y1_test))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7567463377023901\n",
            "[[1055  401]\n",
            " [ 230  908]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.72      0.77      1456\n",
            "           1       0.69      0.80      0.74      1138\n",
            "\n",
            "    accuracy                           0.76      2594\n",
            "   macro avg       0.76      0.76      0.76      2594\n",
            "weighted avg       0.77      0.76      0.76      2594\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gjr-wQsAbl5"
      },
      "source": [
        "Here maximum accuracy is obtained when we use count vectorizer features and Logistic Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DFth3CCA8_A"
      },
      "source": [
        "tweetpos =pd.DataFrame(['''I am very happy today! The atmosphere looks cheerful.Things are looking great. It was such a good day.Success is right around the corner. \n",
        "            Lets celebrate this victory.Everything is more beautiful when you experience them with a smile!'''])\n",
        "tweetneg=pd.DataFrame(['''Now this is my worst, okay? But I am gonna get better.I am tired, boss. Tired of being on the road, lonely as a sparrow in the rain.\n",
        "           I am tired of all the pain I feel.This is quite depressing. I am filled with sorrow.His death broke my heart. It was a sad day.'''])\n"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3r--VJRHCCY",
        "outputId": "0550c534-2849-4754-8e6a-8a4215be261d"
      },
      "source": [
        "# Doing some preprocessing on these tweets as done before\n",
        "tweetpos[0] = tweetpos[0].str.replace('[^\\w\\s]',' ')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "tweetpos[0] = tweetpos[0].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "from textblob import Word\n",
        "tweetpos[0] = tweetpos[0].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "\n",
        "# Extracting Count Vectors feature from our tweets\n",
        "tweetpos_count = count_vect.transform(tweetpos[0])\n",
        "\n",
        "#Predicting the emotion of the tweet using our already trained linear SVM\n",
        "tweetpos_pred = logreg.predict(tweetpos_count)\n",
        "print(tweetpos_pred)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLRC6tmOHEC0",
        "outputId": "744d5ace-e3f0-4ded-870b-2f02c81344ab"
      },
      "source": [
        "# Doing some preprocessing on these tweets as done before\n",
        "tweetneg[0] = tweetneg[0].str.replace('[^\\w\\s]',' ')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "tweetneg[0] = tweetneg[0].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "from textblob import Word\n",
        "tweetneg[0] = tweetneg[0].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "\n",
        "# Extracting Count Vectors feature from our tweets\n",
        "tweetneg_count = count_vect.transform(tweetneg[0])\n",
        "\n",
        "#Predicting the emotion of the tweet using our already trained linear SVM\n",
        "tweetneg_pred = logreg.predict(tweetneg_count)\n",
        "print(tweetneg_pred)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2EZclQ-F7dz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}